{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import modeling_tools as mt\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import murmurhash as mhash\n",
    "\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "\n",
    "# vectorizers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "\n",
    "# feature selectors\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "\n",
    "# scalers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# classifiers\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, Perceptron, SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# samplers\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = pd.read_pickle('../../data/labeled_data_pos_ont_nn_ftweighted.pkl')\n",
    "#drop_trash = (labeled_data['Aggr.Label'] < 90) & (labeled_data['Aggr.Label'] != 12)\n",
    "#drop_trash = (labeled_data['Aggr.Label'] < 90)\n",
    "drop_trash = (labeled_data['Aggr.Label'] < 90) & (labeled_data['NN_bool'] == False)\n",
    "labeled_data = labeled_data[drop_trash]\n",
    "labeled_data['empty'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FT_to_matrix(data):\n",
    "    M = np.zeros((len(data), 100))\n",
    "    for index in range(len(data)):\n",
    "        M[index] = data[index]\n",
    "        \n",
    "    return M + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmat = FT_to_matrix(labeled_data['Raw_FT_mean'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(testmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data['Aggr.Label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features = ['Adjective', 'Verb', 'Noun']\n",
    "ont_features = ['Underspecified', 'Artifact', 'Object', 'Group', 'Human', 'Natural', 'LanguageRepresentation', 'Living', 'GeopoliticalPlace', 'BodyPart', 'Instrument', 'Place', '3rdOrderEntity', 'Mental', 'Purpose', 'Social', 'Institution', 'Plant', 'Imagerepresentation', 'Creature', 'Animal', 'Comestible', 'Quantity', 'Building', 'Substance', 'Part', 'Property', 'BoundedEvent', 'Agentive', 'Communication', 'Garment', 'Furniture', 'Vehicle', '1stOrderEntity', 'Covering', 'Liquid', 'Time', 'UnboundedEvent', 'Physical', 'Dynamic', 'Domain', 'Existence', 'Location', 'Manner', 'Container', 'Condition', 'Static', '2ndOrderEntity', 'Phenomenal', 'MoneyRepresentation', 'Experience', 'Relation', 'Form', 'Representation', 'Stimulating', 'Colour', 'Cause', 'Occupation', 'Possession', 'Artwork', 'Software']\n",
    "numerical_features = ['Raw_len', 'Raw_word_count']\n",
    "categorical_features = ['Label', 'Aggr.Label', 'Source', 'CoderId']\n",
    "text_features = ['Lemma_stripped', 'Raw', 'Lemma']\n",
    "fastt_features = ['Raw_FT_mean', 'Lemma_FT_mean', 'Raw_FT_weighted']\n",
    "empty_features = ['empty'] # for scaling and such when only text\n",
    "features = pos_features + ont_features + numerical_features + categorical_features + text_features + fastt_features + empty_features\n",
    "\n",
    "#numerical_features = ['Raw_len', 'Raw_word_count', 'Underspecified', 'Artifact', 'Object', 'Group', 'Human', 'Natural', 'LanguageRepresentation', 'Living', 'GeopoliticalPlace', 'BodyPart', 'Instrument', 'Place', '3rdOrderEntity', 'Mental', 'Purpose', 'Social', 'Institution', 'Plant', 'Imagerepresentation', 'Creature', 'Animal', 'Comestible', 'Quantity', 'Building', 'Substance', 'Part', 'Property', 'BoundedEvent', 'Agentive', 'Communication', 'Garment', 'Furniture', 'Vehicle', '1stOrderEntity', 'Covering', 'Liquid', 'Time', 'UnboundedEvent', 'Physical', 'Dynamic', 'Domain', 'Existence', 'Location', 'Manner', 'Container', 'Condition', 'Static', '2ndOrderEntity', 'Phenomenal', 'MoneyRepresentation', 'Experience', 'Relation', 'Form', 'Representation', 'Stimulating', 'Colour', 'Cause', 'Occupation', 'Possession', 'Artwork', 'Software']\n",
    "#text_features = ['Lemma_stripped', 'Lemma']\n",
    "#empty_features = ['empty'] # for scaling and such when only text\n",
    "#features = numerical_features + text_features + empty_features\n",
    "#corpus = 'Lemma_stripped'\n",
    "#fastt = 'Raw_FT_mean'\n",
    "fastt = 'Raw_FT_weighted'\n",
    "corpus = 'Lemma'\n",
    "target = 'Aggr.Label'\n",
    "#target = 'Label'\n",
    "\n",
    "train_X, validation_X, train_y, validation_y = train_test_split(\n",
    "    labeled_data[features],\n",
    "    labeled_data[target],\n",
    "    test_size=0.33,\n",
    "    random_state=1,\n",
    "    stratify=labeled_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PassThrough(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, x):\n",
    "        return x\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer params\n",
    "TfidfVectorizer_params = list(ParameterGrid({\n",
    "    'strip_accents': ['ascii', 'unicode', None],\n",
    "    'max_df': [round(0.1*x, 2) for x in range(3,11,2)] + [1],\n",
    "    'max_features': [1000*x for x in range(5,50,20)] + [None],\n",
    "    'norm': ['l2', None],\n",
    "    'use_idf': [True, False]\n",
    "}))\n",
    "\n",
    "CountVectorizer_params = list(ParameterGrid({\n",
    "    'strip_accents': ['ascii', 'unicode', None],\n",
    "    'max_df': [round(0.1*x, 2) for x in range(3,11,2)] + [1],\n",
    "    'max_features': [1000*x for x in range(5,50,20)] + [None],\n",
    "}))\n",
    "\n",
    "HashingVectorizer_params = list(ParameterGrid({\n",
    "    'strip_accents': ['ascii', 'unicode', None],\n",
    "    'n_features': [2**x for x in range(15,25,2)],\n",
    "    'norm': ['l2'],\n",
    "    'alternate_sign': [False]\n",
    "}))\n",
    "\n",
    "# feature selector params\n",
    "SelectKBest_params = list(ParameterGrid({\n",
    "    'score_func': [chi2, f_classif],\n",
    "    'k': [25000,30000,35000,40000,50000]\n",
    "}))\n",
    "\n",
    "# scaler params\n",
    "MinMaxScaler_params = list(ParameterGrid({\n",
    "    'feature_range': [(0,1)]\n",
    "}))\n",
    "\n",
    "# classifier params\n",
    "MultinomialNB_params = list(ParameterGrid({\n",
    "    'alpha': [0.01, 0.0015, 0.001, 0.0005, 0.0001]\n",
    "}))\n",
    "\n",
    "LinearSVC_params = list(ParameterGrid({\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'tol': [0.01, 0.001, 0.0001, 0.00001],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'class_weight': ['balanced', None]\n",
    "}))\n",
    "\n",
    "ComplementNB_params = list(ParameterGrid({\n",
    "    'alpha': [0.01,0.001,0.0001],\n",
    "    'norm': [True, False]    \n",
    "}))\n",
    "\n",
    "SGDClassifier_params = list(ParameterGrid({\n",
    "    'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge'],\n",
    "    'alpha': [0.1,0.01,0.001,0.0001],\n",
    "    'n_jobs': [-1]\n",
    "}))\n",
    "\n",
    "# sampler params\n",
    "ClusterCentroids_params = list(ParameterGrid({\n",
    "    'random_state': [1],\n",
    "    'sampling_strategy': ['majority', 'not minority', 'all'],\n",
    "    'n_jobs': [-1]\n",
    "}))\n",
    "\n",
    "RandomUnderSampler_params = list(ParameterGrid({\n",
    "    'random_state': [1],\n",
    "    'sampling_strategy': ['majority', 'auto'],\n",
    "    'replacement': [True, False]\n",
    "}))\n",
    "\n",
    "TomekLinks_params = list(ParameterGrid({\n",
    "    'random_state': [1],\n",
    "    'sampling_strategy': ['majority', 'auto'],\n",
    "    'n_jobs': [-1]\n",
    "}))\n",
    "\n",
    "ADASYN_params = list(ParameterGrid({\n",
    "    'random_state': [1],\n",
    "    'sampling_strategy': ['minority', 'auto'],\n",
    "    'n_neighbors': [3,5,7,13],\n",
    "    'n_jobs': [-1]\n",
    "}))\n",
    "\n",
    "SMOTE_params = list(ParameterGrid({\n",
    "    'random_state': [1],\n",
    "    'sampling_strategy': ['minority', 'auto'],\n",
    "    'k_neighbors': [3,5,7,13],\n",
    "    'n_jobs': [-1]\n",
    "}))\n",
    "\n",
    "RandomOverSampler_params = list(ParameterGrid({\n",
    "    'random_state': [1],\n",
    "    'sampling_strategy': ['minority', 'auto']\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_TextDLWC/TfidfVectorizer/EnsembleClassifier/SMOTE/SelectKBest/MinMaxScaler\n",
      "{'max_df': 0.3, 'max_features': None, 'norm': 'l2', 'strip_accents': 'ascii', 'use_idf': False}\n",
      "{'binary_clf': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'binary_clf_params': {'solver': 'lbfgs'}, 'bucket_clf': <class 'sklearn.naive_bayes.MultinomialNB'>, 'bucket_clf_params': {'alpha': 0.001}, 'judge': MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)}\n",
      "{'random_state': 1, 'sampling_strategy': 'minority', 'k_neighbors': 7, 'n_jobs': -1}\n",
      "{'score_func': <function f_classif at 0x0000016AA6810400>, 'k': 35000}\n",
      "{'feature_range': (0, 1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nils\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44367062679229824 0.40238587525438246 0.3837511606925739 0.3876020941361554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nils\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>V.params</th>\n",
       "      <th>Selector</th>\n",
       "      <th>Sel.params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Sca.params</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>C.params</th>\n",
       "      <th>Sampler</th>\n",
       "      <th>S.params</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0_TextDLWC/TfidfVectorizer/EnsembleClassifier/SMOTE/SelectKBest/MinMaxScaler</td>\n",
       "      <td>TextDLWC</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>{'max_df': 0.3, 'max_features': None, 'norm': ...</td>\n",
       "      <td>SelectKBest</td>\n",
       "      <td>{'score_func': &lt;function f_classif at 0x000001...</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>{'feature_range': (0, 1)}</td>\n",
       "      <td>EnsembleClassifier</td>\n",
       "      <td>{'binary_clf': &lt;class 'sklearn.linear_model.lo...</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>{'random_state': 1, 'sampling_strategy': 'mino...</td>\n",
       "      <td>0.443671</td>\n",
       "      <td>0.402386</td>\n",
       "      <td>0.383751</td>\n",
       "      <td>0.387602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Features       Vectorizer  \\\n",
       "0_TextDLWC/TfidfVectorizer/EnsembleClassifier/S...  TextDLWC  TfidfVectorizer   \n",
       "\n",
       "                                                                                             V.params  \\\n",
       "0_TextDLWC/TfidfVectorizer/EnsembleClassifier/S...  {'max_df': 0.3, 'max_features': None, 'norm': ...   \n",
       "\n",
       "                                                       Selector  \\\n",
       "0_TextDLWC/TfidfVectorizer/EnsembleClassifier/S...  SelectKBest   \n",
       "\n",
       "                                                                                           Sel.params  \\\n",
       "0_TextDLWC/TfidfVectorizer/EnsembleClassifier/S...  {'score_func': <function f_classif at 0x000001...   \n",
       "\n",
       "                                                          Scaler  \\\n",
       "0_TextDLWC/TfidfVectorizer/EnsembleClassifier/S...  MinMaxScaler   \n",
       "\n",
       "                                                                   Sca.params  \\\n",
       "0_TextDLWC/TfidfVectorizer/EnsembleClassifier/S...  {'feature_range': (0, 1)}   \n",
       "\n",
       "                                                            Classifier  \\\n",
       "0_TextDLWC/TfidfVectorizer/EnsembleClassifier/S...  EnsembleClassifier   \n",
       "\n",
       "                                                                                             C.params  \\\n",
       "0_TextDLWC/TfidfVectorizer/EnsembleClassifier/S...  {'binary_clf': <class 'sklearn.linear_model.lo...   \n",
       "\n",
       "                                                   Sampler  \\\n",
       "0_TextDLWC/TfidfVectorizer/EnsembleClassifier/S...   SMOTE   \n",
       "\n",
       "                                                                                             S.params  \\\n",
       "0_TextDLWC/TfidfVectorizer/EnsembleClassifier/S...  {'random_state': 1, 'sampling_strategy': 'mino...   \n",
       "\n",
       "                                                    Accuracy  Precision  \\\n",
       "0_TextDLWC/TfidfVectorizer/EnsembleClassifier/S...  0.443671   0.402386   \n",
       "\n",
       "                                                      Recall    Fscore  \n",
       "0_TextDLWC/TfidfVectorizer/EnsembleClassifier/S...  0.383751  0.387602  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature combinations\n",
    "feats = [\n",
    "    #('TextOnly', False),\n",
    "    #('TextPOS', pos_features),\n",
    "    #('TextONT', ont_features),\n",
    "    ('TextDLWC', numerical_features),\n",
    "    #('All', pos_features + ont_features + numerical_features),\n",
    "]\n",
    "\n",
    "# vectorizers\n",
    "vectorizers = [\n",
    "    #('No_vectorizer', PassThrough, [{}]),\n",
    "    #('TfidfVectorizer', TfidfVectorizer, [{}]),\n",
    "    ('TfidfVectorizer', TfidfVectorizer, [{'max_df': 0.3, 'max_features': None, 'norm': 'l2', 'strip_accents': 'ascii', 'use_idf': False}]),\n",
    "    #('TfidfVectorizer', TfidfVectorizer, TfidfVectorizer_params),\n",
    "    #('CountVectorizer', CountVectorizer, CountVectorizer_params),\n",
    "    #('HashingVectorizer', HashingVectorizer, HashingVectorizer_params),  \n",
    "]\n",
    "\n",
    "#corpus = ['empty']\n",
    "#fastt = False\n",
    "\n",
    "# feature selectors\n",
    "selectors = [\n",
    "    #('No_selector', PassThrough, [{}]),\n",
    "    ('SelectKBest', SelectKBest, [{'score_func': f_classif, 'k': 35000}]),\n",
    "    #('SelectKBest', SelectKBest, SelectKBest_params),\n",
    "]\n",
    "\n",
    "# scalers\n",
    "scalers = [\n",
    "    #('No_scaling', PassThrough, [{}]),\n",
    "    ('MinMaxScaler', MinMaxScaler, [{'feature_range': (0,1)}])\n",
    "    #('MinMaxScaler', MinMaxScaler, MinMaxScaler_params),\n",
    "]\n",
    "\n",
    "# classifiers\n",
    "classifiers = [\n",
    "    #('MultinomialNB', MultinomialNB, MultinomialNB_params),\n",
    "    #('LinearSVC', LinearSVC, LinearSVC_params),\n",
    "    #('ComplementNB', ComplementNB, ComplementNB_params),\n",
    "    #('SGDClassifier', SGDClassifier, SGDClassifier_params)\n",
    "    #('MultinomialNB', MultinomialNB, [{'alpha': 0.001}]),\n",
    "    #('LinearSVC', LinearSVC, [{'C': 0.1, 'class_weight': None, 'loss': 'squared_hinge', 'tol': 0.01}]),\n",
    "    #('ComplementNB', ComplementNB, [{'alpha': 0.01, 'norm': False}]),\n",
    "    #('SGDClassifier', SGDClassifier, [{'alpha': 0.01, 'loss': 'hinge', 'n_jobs': -1}]),\n",
    "    #('LogisticRegression', LogisticRegression, [{'solver': 'lbfgs', 'multi_class': 'multinomial'}]),\n",
    "    #('XGBClassifier', XGBClassifier, [{}]),\n",
    "    #('BucketClassifier', mt.BucketClassifier, [{'hashfunc': mhash, 'classifiers': [LogisticRegression(**{'solver': 'lbfgs', 'multi_class': 'multinomial'}) for _ in range(10)], 'judge': MultinomialNB(alpha=0.001), 'num_buckets': 8}]),\n",
    "    ('EnsembleClassifier', mt.EnsembleClassifier, [{'binary_clf': LogisticRegression, 'binary_clf_params': {'solver': 'lbfgs'}, 'bucket_clf': MultinomialNB, 'bucket_clf_params': {'alpha': 0.001}, 'judge': MultinomialNB(alpha=0.001)}]),\n",
    "]\n",
    "\n",
    "\n",
    "# samplers\n",
    "samplers = [\n",
    "    ('SMOTE', SMOTE, [{'random_state': 1, 'sampling_strategy': 'minority', 'k_neighbors': 7, 'n_jobs': -1}]),\n",
    "    #('No_sampling', PassThrough, [{}]),\n",
    "    #('ClusterCentroids', ClusterCentroids, ClusterCentroids_params),\n",
    "    #('RandomUnderSampler', RandomUnderSampler, RandomUnderSampler_params),\n",
    "    #('TomekLinks', TomekLinks, TomekLinks_params),\n",
    "    #('ADASYN', ADASYN, ADASYN_params),\n",
    "    #('SMOTE', SMOTE, SMOTE_params),\n",
    "    #('RandomOverSampler', RandomOverSampler, RandomOverSampler_params),\n",
    "]\n",
    "\n",
    "\n",
    "# run the worker functions with above configurations\n",
    "results, preds_validation = mt.worker(\n",
    "    train_X, train_y, validation_X, validation_y,\n",
    "    vectorizers, selectors, scalers, classifiers, samplers,\n",
    "    corpus, feats, False\n",
    ")\n",
    "'''\n",
    "timestamp = str(round(time.time()))\n",
    "results.to_pickle('../../stats/'+timestamp+'_results_features_scaling_best.pkl')\n",
    "with open('../../stats/'+timestamp+'_preds_features_scaling_best.pkl', 'wb') as f:\n",
    "    pickle.dump(preds_validation, f, pickle.HIGHEST_PROTOCOL)\n",
    "'''\n",
    "display(results.sort_values(by=['Accuracy', 'Precision'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = str(round(time.time()))\n",
    "results.to_pickle('../../stats/'+timestamp+'_results_selectors.pkl')\n",
    "with open('../../stats/'+timestamp+'_preds_selectors.pkl', 'wb') as f:\n",
    "    pickle.dump(preds_validation, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified = preds_validation['validation_y'] != preds_validation['preds'][0]\n",
    "correctly = preds_validation['validation_y'] == preds_validation['preds'][0]\n",
    "\n",
    "validation_X[corpus][misclassified].sample(n=5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_results = pd.read_pickle('../../stats/1571607882_results_POSandONT_MultinomialNB_best_TfidfVectorizer_best.pkl')\n",
    "\n",
    "with open('../../stats/1571607882_preds_POSandONT_MultinomialNB_best_TfidfVectorizer_best.pkl', 'rb') as f:\n",
    "    loaded_preds_validation = pickle.load(f)\n",
    "\n",
    "display(loaded_results.sort_values(by=['Precision','Accuracy'], ascending=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_results.sort_values(by=['Precision','Accuracy'], ascending=False).groupby('Sampler').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = mt.plot_cf(preds_validation['validation_y'], preds_validation['preds'][0], title = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
