{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = pd.read_pickle('../../data/labeled_data_pos_ont_nn.pkl')\n",
    "drop_trash = (labeled_data['Aggr.Label'] < 90) & (labeled_data['NN_bool'] == False)\n",
    "labeled_data = labeled_data[drop_trash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features = ['Adjective', 'Verb', 'Noun']\n",
    "ont_features = ['Underspecified', 'Artifact', 'Object', 'Group', 'Human', 'Natural', 'LanguageRepresentation', 'Living', 'GeopoliticalPlace', 'BodyPart', 'Instrument', 'Place', '3rdOrderEntity', 'Mental', 'Purpose', 'Social', 'Institution', 'Plant', 'Imagerepresentation', 'Creature', 'Animal', 'Comestible', 'Quantity', 'Building', 'Substance', 'Part', 'Property', 'BoundedEvent', 'Agentive', 'Communication', 'Garment', 'Furniture', 'Vehicle', '1stOrderEntity', 'Covering', 'Liquid', 'Time', 'UnboundedEvent', 'Physical', 'Dynamic', 'Domain', 'Existence', 'Location', 'Manner', 'Container', 'Condition', 'Static', '2ndOrderEntity', 'Phenomenal', 'MoneyRepresentation', 'Experience', 'Relation', 'Form', 'Representation', 'Stimulating', 'Colour', 'Cause', 'Occupation', 'Possession', 'Artwork', 'Software']\n",
    "numerical_features = ['Raw_len', 'Raw_word_count']\n",
    "categorical_features = ['Label', 'Aggr.Label', 'Source', 'CoderId']\n",
    "text_features = ['Lemma_stripped', 'Raw', 'Lemma']\n",
    "fastt_features = ['Raw_FT_mean', 'Lemma_FT_mean']\n",
    "features = pos_features + ont_features + numerical_features + text_features + fastt_features + categorical_features\n",
    "\n",
    "fastt = 'Raw_FT_mean'\n",
    "corpus = 'Lemma'\n",
    "target = 'Aggr.Label'\n",
    "#target = 'Label'\n",
    "\n",
    "\n",
    "train_X, validation_X, train_y, validation_y = train_test_split(\n",
    "    labeled_data[features],\n",
    "    labeled_data[target],\n",
    "    test_size=0.33,\n",
    "    random_state=1,\n",
    "    stratify=labeled_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(**{'tokenizer': lambda x: x.split(), 'max_df': 0.3, 'max_features': None, 'norm': 'l2', 'use_idf': False})\n",
    "train_x = vectorizer.fit_transform(train_X[corpus])\n",
    "validation_x = vectorizer.transform(validation_X[corpus])\n",
    "\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_tfidf_means(X, Y, c, words, n):\n",
    "    class_ids = np.where(Y == c)\n",
    "    return sorted( list( zip(words, X[class_ids].mean(0).getA1())), key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "def get_corpus_tfidf_means(words, X, n):\n",
    "    return sorted( list( zip(words, X.mean(0).getA1())), key=lambda x: x[1], reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accumulated_ranks(words, X, n):\n",
    "    l = len(words)\n",
    "\n",
    "    counts = Counter()\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        \n",
    "        row = np.squeeze(X[i].toarray())\n",
    "        top_id = np.argsort(row)[::-1][:10]\n",
    "        counts.update([words[k] for k in top_id if row[k] != 0])\n",
    "\n",
    "    count_words = [(k, v) for k,v in counts.items()]\n",
    "\n",
    "    return sorted( count_words, key=lambda x: x[1], reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-b6293e4833d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcount_corpus_top\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_accumulated_ranks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-2729a6fdfc20>\u001b[0m in \u001b[0;36mget_accumulated_ranks\u001b[1;34m(words, X, n)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mtop_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mcounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtop_id\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n\u001b[0;32m   1032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m     \"\"\"\n\u001b[1;32m-> 1034\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argsort'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count_corpus_top = get_accumulated_ranks(words, train_x, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hun',\n",
       " 'norge',\n",
       " 'norsk',\n",
       " 'du',\n",
       " 'krone',\n",
       " 'prosent',\n",
       " 'man',\n",
       " 'land',\n",
       " 'oslo',\n",
       " 'politi',\n",
       " 'mann',\n",
       " 'gar',\n",
       " 'mene',\n",
       " 'million',\n",
       " 'sak',\n",
       " 'selskap',\n",
       " 'vg',\n",
       " 'barn',\n",
       " 'kvinne',\n",
       " 'liten',\n",
       " 'slik',\n",
       " 'vise',\n",
       " 'gammel',\n",
       " 'usa',\n",
       " 'der',\n",
       " 'hva',\n",
       " 'finne',\n",
       " 'var',\n",
       " 'bruke',\n",
       " 'tid',\n",
       " 'tro',\n",
       " 'gang',\n",
       " 'aring',\n",
       " 'ntb',\n",
       " 'ke',\n",
       " 'denne',\n",
       " 'tidlig',\n",
       " 'skrive',\n",
       " 'folk',\n",
       " 'parti',\n",
       " 'milliard',\n",
       " 'bil',\n",
       " 'under',\n",
       " 'hvor',\n",
       " 'sist',\n",
       " 'tre',\n",
       " 'min',\n",
       " 'eu',\n",
       " 'siden',\n",
       " 'mellom',\n",
       " 'iflge',\n",
       " 'rett',\n",
       " 'kommune',\n",
       " 'viktig',\n",
       " '000',\n",
       " 'hans',\n",
       " 'burde',\n",
       " 'leder',\n",
       " 'uke',\n",
       " 'regjering',\n",
       " 'menneske',\n",
       " 'person',\n",
       " 'aftenposten',\n",
       " 'verden',\n",
       " 'liv',\n",
       " 'penge',\n",
       " 'president',\n",
       " 'skole',\n",
       " 'hy',\n",
       " 'mte',\n",
       " 'frste',\n",
       " 'ingen',\n",
       " 'lang',\n",
       " 'sta',\n",
       " 'politisk',\n",
       " 'nske',\n",
       " 'pris',\n",
       " 'legge',\n",
       " 'egen',\n",
       " 'drepe',\n",
       " 'fortelle',\n",
       " 'her',\n",
       " 'rundt',\n",
       " 'skje',\n",
       " 'kamp',\n",
       " 'selge',\n",
       " 'ansatt',\n",
       " 'tall',\n",
       " 'by',\n",
       " 'hvis',\n",
       " '10',\n",
       " 'tv',\n",
       " 'bade',\n",
       " 'jobb',\n",
       " 'ned',\n",
       " 'fire',\n",
       " 'fjor',\n",
       " 'ap',\n",
       " 'jente',\n",
       " 'amerikansk']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in count_corpus_top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['norsk',\n",
       " 'norge',\n",
       " 'land',\n",
       " 'prosent',\n",
       " 'krone',\n",
       " 'ke',\n",
       " 'usa',\n",
       " 'sverige',\n",
       " 'mene',\n",
       " 'du',\n",
       " 'svensk',\n",
       " 'ntb',\n",
       " 'verden',\n",
       " 'hun',\n",
       " 'million',\n",
       " 'vare',\n",
       " 'eu',\n",
       " 'handle',\n",
       " 'aftenposten',\n",
       " 'mellom',\n",
       " 'slik',\n",
       " 'toll',\n",
       " 'man',\n",
       " 'nordmann',\n",
       " 'sist']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in get_class_tfidf_means(train_x, train_y, 18, words, 25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hun', 0.03679772952281546),\n",
       " ('norsk', 0.032547337712039145),\n",
       " ('$?', 0.031215093265825822),\n",
       " ('norge', 0.03078468777543775),\n",
       " ('du', 0.02734389331220279),\n",
       " ('krone', 0.025892148537540866),\n",
       " ('mene', 0.02550733003104852),\n",
       " ('prosent', 0.02498723745219147),\n",
       " ('man', 0.0235673563033522),\n",
       " ('går', 0.023197255884258423),\n",
       " ('land', 0.022996185569323466),\n",
       " ('liten', 0.022224659969511822),\n",
       " ('før', 0.021936021176808092),\n",
       " ('slik', 0.021642812312290892),\n",
       " ('mann', 0.02075133781561205),\n",
       " ('denne', 0.020519954113338096),\n",
       " ('der', 0.020233468856998314),\n",
       " ('oslo', 0.019890461463660757),\n",
       " ('vise', 0.01936214164949951),\n",
       " ('tid', 0.019200190869811874),\n",
       " ('million', 0.018791269833757673),\n",
       " ('gang', 0.01839503592427513),\n",
       " ('politi', 0.018076763036248552),\n",
       " ('hva', 0.017744077141693137),\n",
       " ('stå', 0.01759687949630474),\n",
       " ('sist', 0.01741824791239221),\n",
       " ('tidlig', 0.01724624315406099),\n",
       " ('bruke', 0.017168844291142744),\n",
       " ('under', 0.017140408578401573),\n",
       " ('sak', 0.016708868127309186),\n",
       " ('siden', 0.0166082939011914),\n",
       " ('finne', 0.01654372578934111),\n",
       " ('tre', 0.01644197434217084),\n",
       " ('barn', 0.016437576639752004),\n",
       " ('ntb', 0.01617311893422789),\n",
       " ('hvor', 0.016170091650124344),\n",
       " ('lang', 0.01599420002481259),\n",
       " ('tro', 0.015905524978207405),\n",
       " ('vår', 0.015702512302215952),\n",
       " ('ingen', 0.015691811871847476),\n",
       " ('mellom', 0.015616579922387084),\n",
       " ('legge', 0.0153931153368017),\n",
       " ('vg', 0.015303184887089144),\n",
       " ('ifølge', 0.015143372828742226),\n",
       " ('både', 0.014873476279278316),\n",
       " ('gammel', 0.014861714813489716),\n",
       " ('blant', 0.014851589710515175),\n",
       " ('første', 0.014756380971136063),\n",
       " ('skrive', 0.014737370917684742),\n",
       " ('viktig', 0.014375879670258676),\n",
       " ('kvinne', 0.013230483123097294),\n",
       " ('rett', 0.013198023408093151),\n",
       " ('noe', 0.013187460723819606),\n",
       " ('egen', 0.013161065597528084),\n",
       " ('rundt', 0.01314156635374385),\n",
       " ('uke', 0.013113168785787832),\n",
       " ('ønske', 0.012979681983043235),\n",
       " ('selskap', 0.012923687343783019),\n",
       " ('sette', 0.012867414618038493),\n",
       " ('folk', 0.01274537984969317),\n",
       " ('del', 0.012699174711141374),\n",
       " ('øke', 0.0126936586341891),\n",
       " ('her', 0.012553392475633222),\n",
       " ('skje', 0.012445286820350548),\n",
       " ('samme', 0.01216965469856032),\n",
       " ('frem', 0.012161116723175725),\n",
       " ('hans', 0.012082369921270316),\n",
       " ('uten', 0.011936436737000514),\n",
       " ('burde', 0.01183229280951153),\n",
       " ('hvis', 0.011632257776361211),\n",
       " ('høy', 0.01156838015547561),\n",
       " ('nok', 0.011433231566653051),\n",
       " ('mens', 0.011383613389888742),\n",
       " ('hver', 0.011294586871832185),\n",
       " ('ligge', 0.011269789489870539),\n",
       " ('$!', 0.011232314343863988),\n",
       " ('én', 0.011093432289178752),\n",
       " ('fordi', 0.011037677580490462),\n",
       " ('usa', 0.010980230314170602),\n",
       " ('sammen', 0.0109077993094033),\n",
       " ('disse', 0.010874043254960282),\n",
       " ('vite', 0.010791393467341925),\n",
       " ('møte', 0.010722539417033666),\n",
       " ('verden', 0.010483438645579643),\n",
       " ('fjor', 0.010464077901092269),\n",
       " ('igjen', 0.010400437324681076),\n",
       " ('holde', 0.010337447023906494),\n",
       " ('fortelle', 0.010293420080171112),\n",
       " ('grunn', 0.010257176258026954),\n",
       " ('ned', 0.010226374734825563),\n",
       " ('person', 0.010126497950161139),\n",
       " ('gjennom', 0.010075383898311098),\n",
       " ('liv', 0.009983330714405814),\n",
       " ('leder', 0.009909231959769187),\n",
       " ('sted', 0.009844774776996657),\n",
       " ('menneske', 0.009834576806238591),\n",
       " ('penge', 0.009691767237854709),\n",
       " ('derfor', 0.009623293088282858),\n",
       " ('klar', 0.009620103036348525),\n",
       " ('min', 0.009571433798069903)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_top = get_corpus_tfidf_means(words, train_x, 100)\n",
    "corpus_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hun',\n",
       " 'norsk',\n",
       " 'norge',\n",
       " 'du',\n",
       " 'krone',\n",
       " 'mene',\n",
       " 'prosent',\n",
       " 'land',\n",
       " 'man',\n",
       " 'gar',\n",
       " 'liten',\n",
       " 'oslo',\n",
       " 'slik',\n",
       " 'mann',\n",
       " 'tid',\n",
       " 'denne',\n",
       " 'der',\n",
       " 'vise',\n",
       " 'million',\n",
       " 'ntb',\n",
       " 'gang',\n",
       " 'politi',\n",
       " 'sak',\n",
       " 'hva',\n",
       " 'sta']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in corpus_top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_intersect = set([x[0] for x in count_corpus_top]) & set([x[0] for x in corpus_top])\n",
    "corpus_intersect_prop = len(corpus_intersect)/100\n",
    "corpus_intersect_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.73 0.03465671190031781\n",
      "2 0.83 0.022801795893658883\n",
      "3 0.82 0.07430762245876002\n",
      "4 0.8 0.03743126671038693\n",
      "5 0.73 0.023911617817686526\n",
      "6 0.72 0.029460727437824748\n",
      "7 0.79 0.026686172627755637\n",
      "8 0.76 0.03157947838369571\n",
      "9 0.84 0.022297331382737224\n",
      "10 0.77 0.05695404328305504\n",
      "12 0.77 0.1344397921606215\n",
      "13 0.82 0.03611965898199062\n",
      "14 0.75 0.019371437219391614\n",
      "15 0.78 0.0811178933562024\n",
      "16 0.79 0.08096655400292589\n",
      "17 0.82 0.05513797104373707\n",
      "18 0.65 0.005599556071230389\n",
      "19 0.76 0.04787368208646522\n",
      "20 0.77 0.07592190889370933\n",
      "21 0.74 0.00721384250617969\n",
      "23 0.83 0.0320334964435252\n",
      "24 0.72 0.01992634818140544\n",
      "25 0.61 0.026686172627755637\n",
      "26 0.81 0.017504918528981485\n"
     ]
    }
   ],
   "source": [
    "class_labels = np.unique(train_y)\n",
    "corpus_top_words = set([t[0] for t in corpus_top])\n",
    "\n",
    "for c in class_labels:\n",
    "    top = get_class_tfidf_means(train_x, train_y, c, words, len(corpus_top_words))\n",
    "    top_words = set([t[0] for t in top])\n",
    "    intersect = top_words & corpus_top_words\n",
    "    intersect_prop = len(intersect)/len(corpus_top_words)\n",
    "    class_prop = len(np.where(train_y == c)[0]) / len(train_y)\n",
    "    print(c,intersect_prop, class_prop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>norsk</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>norge</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>land</td>\n",
       "      <td>3</td>\n",
       "      <td>0.049224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>prosent</td>\n",
       "      <td>4</td>\n",
       "      <td>0.047468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>krone</td>\n",
       "      <td>5</td>\n",
       "      <td>0.038828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ke</td>\n",
       "      <td>6</td>\n",
       "      <td>0.035839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>usa</td>\n",
       "      <td>7</td>\n",
       "      <td>0.031895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>sverige</td>\n",
       "      <td>8</td>\n",
       "      <td>0.031859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>mene</td>\n",
       "      <td>9</td>\n",
       "      <td>0.030514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>du</td>\n",
       "      <td>10</td>\n",
       "      <td>0.028623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>svensk</td>\n",
       "      <td>11</td>\n",
       "      <td>0.026646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>ntb</td>\n",
       "      <td>12</td>\n",
       "      <td>0.026629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>verden</td>\n",
       "      <td>13</td>\n",
       "      <td>0.025813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>hun</td>\n",
       "      <td>14</td>\n",
       "      <td>0.023392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>million</td>\n",
       "      <td>15</td>\n",
       "      <td>0.022931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>vare</td>\n",
       "      <td>16</td>\n",
       "      <td>0.022263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>eu</td>\n",
       "      <td>17</td>\n",
       "      <td>0.022228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>handle</td>\n",
       "      <td>18</td>\n",
       "      <td>0.022199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>aftenposten</td>\n",
       "      <td>19</td>\n",
       "      <td>0.022050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>mellom</td>\n",
       "      <td>20</td>\n",
       "      <td>0.021740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>slik</td>\n",
       "      <td>21</td>\n",
       "      <td>0.020741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>toll</td>\n",
       "      <td>22</td>\n",
       "      <td>0.020642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>man</td>\n",
       "      <td>23</td>\n",
       "      <td>0.020641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>nordmann</td>\n",
       "      <td>24</td>\n",
       "      <td>0.020591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>sist</td>\n",
       "      <td>25</td>\n",
       "      <td>0.020300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word   y         x\n",
       "0         norsk   1  0.062554\n",
       "1         norge   2  0.053563\n",
       "2          land   3  0.049224\n",
       "3       prosent   4  0.047468\n",
       "4         krone   5  0.038828\n",
       "5            ke   6  0.035839\n",
       "6           usa   7  0.031895\n",
       "7       sverige   8  0.031859\n",
       "8          mene   9  0.030514\n",
       "9            du  10  0.028623\n",
       "10       svensk  11  0.026646\n",
       "11          ntb  12  0.026629\n",
       "12       verden  13  0.025813\n",
       "13          hun  14  0.023392\n",
       "14      million  15  0.022931\n",
       "15         vare  16  0.022263\n",
       "16           eu  17  0.022228\n",
       "17       handle  18  0.022199\n",
       "18  aftenposten  19  0.022050\n",
       "19       mellom  20  0.021740\n",
       "20         slik  21  0.020741\n",
       "21         toll  22  0.020642\n",
       "22          man  23  0.020641\n",
       "23     nordmann  24  0.020591\n",
       "24         sist  25  0.020300"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "test_class_ids = np.where(train_y == 18)\n",
    "\n",
    "\n",
    "df = get_class_tfidf_means(train_x, test_class_ids, words)\n",
    "#ax = df.plot.scatter(x='x', y='y')\n",
    "#df[['x', 'y', 'word']].apply(lambda x: ax.text(*x, rotation=0, rotation_mode='anchor'), axis=1);\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 960101, 1222831,  902857,  416490,  463979, 1328550, 1528755,\n",
       "            1372426,  941033,  534793,\n",
       "            ...\n",
       "            1023255,  676612,  595193, 1260345,  589074,  304335, 1102365,\n",
       "             304338,  199586,  108149],\n",
       "           dtype='int64', length=111)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[train_y == 18].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_tfidf(words, tfidfs, n):\n",
    "    return sorted( list( zip(words, tfidfs.sum(0).getA1())), key=lambda x: x[1], reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hun', 722.3461070988958),\n",
       " ('norsk', 646.7482907609138),\n",
       " ('norge', 645.099634864106),\n",
       " ('du', 545.4351939279998),\n",
       " ('krone', 507.0044142288883),\n",
       " ('mene', 498.6395830356461),\n",
       " ('prosent', 492.30294291879756),\n",
       " ('land', 473.67226522662304),\n",
       " ('man', 468.7542134495717),\n",
       " ('gar', 451.9632494334225),\n",
       " ('liten', 437.3297834967681),\n",
       " ('oslo', 426.6713503319191),\n",
       " ('slik', 425.65661873005354),\n",
       " ('mann', 414.7627044936016),\n",
       " ('tid', 403.6408219285322),\n",
       " ('denne', 403.1271653656752),\n",
       " ('der', 397.60581887386127),\n",
       " ('vise', 380.1452738795548),\n",
       " ('million', 369.0178088934919),\n",
       " ('ntb', 368.31644806180367),\n",
       " ('gang', 362.18831341932486),\n",
       " ('politi', 361.0660631324958),\n",
       " ('sak', 355.7012177140237),\n",
       " ('hva', 354.68436592567406),\n",
       " ('sta', 347.0451685107662)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_corpus_tfidf(words, train_x, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_KBest(words, c, K, x, y):\n",
    "    \n",
    "    words = np.array(words)\n",
    "    msk = np.zeros(words.shape[0], dtype=bool)\n",
    "    for cl in c:\n",
    "        class_y = y.copy()\n",
    "        class_y[class_y != cl] = 0\n",
    "        selected = SelectKBest(chi2, k=K).fit(x, class_y)\n",
    "        selected_words = selected.get_support()\n",
    "        msk = msk | selected_words\n",
    "        \n",
    "    return words[msk]\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vocab = get_class_KBest(words, class_labels, 100, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2022', 'afghanistan', 'aksje', 'ambassade', 'ambassadør',\n",
       "       'angrep', 'arbeidsgiver', 'arbeidsliv', 'arbeidstager',\n",
       "       'arbeidstilsynet', 'asyl', 'asylmottak', 'asylsøker', 'asylsøknad',\n",
       "       'avis', 'bank', 'barn', 'barnehage', 'barnehageplass', 'barnevern',\n",
       "       'bedrift', 'behandling', 'bibliotek', 'bil', 'bilist', 'biskop',\n",
       "       'blatter', 'bolig', 'boligmarked', 'boligpris', 'bombe', 'bonde',\n",
       "       'brann', 'brannvesen', 'burka', 'børs', 'digital',\n",
       "       'diskriminering', 'dnb', 'doggerland', 'drap', 'drepe', 'dyr',\n",
       "       'dømme', 'e18', 'eiendom', 'eiendomsmegler', 'eiendomsskatt',\n",
       "       'elbil', 'elev', 'enso', 'eu', 'eu-medlemskap', 'evakuere', 'fag',\n",
       "       'fengsel', 'ferdsel', 'festekontrakt', 'fifa', 'fisk', 'fly',\n",
       "       'flyktning', 'fn', 'forelder', 'forlag', 'forsvaret', 'fosterhjem',\n",
       "       'fotballforbund', 'frp', 'gjedrem', 'global', 'grensehandel',\n",
       "       'grimsdalshytta', 'gud', 'helse', 'helseminister', 'helsetilsynet',\n",
       "       'hijab', 'homofil', 'hund', 'hydro', 'hytte', 'høyre', 'høyskole',\n",
       "       'idrett', 'imf', 'innvandrer', 'innvandring', 'ioc', 'irak',\n",
       "       'israelsk', 'jordskjelv', 'jøde', 'kanal', 'katolsk', 'kina',\n",
       "       'kirke', 'kirken', 'kjøre', 'kjøtt', 'klimaendring', 'klimagass',\n",
       "       'klimapanel', 'kontantstøtte', 'kreft', 'krig', 'kristen', 'krone',\n",
       "       'kulturdepartementet', 'kulturminister', 'kulturrådet', 'kunde',\n",
       "       'kunst', 'kunstner', 'kværner', 'laks', 'land', 'ledighet', 'lege',\n",
       "       'leilighet', 'likestilling', 'lo', 'lærer', 'lønn', 'mann',\n",
       "       'masai', 'mat', 'mattilsynet', 'medisin', 'megler', 'menighet',\n",
       "       'menneskerettighet', 'militær', 'miljøvennlig', 'million', 'mobil',\n",
       "       'mor', 'mottak', 'muhammed', 'museum', 'nasjonalgalleriet',\n",
       "       'nasjonalmuseet', 'nasjonalpark', 'nav', 'netcom', 'nff', 'nif',\n",
       "       'nrk', 'nsb', 'ol', 'olje', 'olje-', 'oljepris', 'oljeselskap',\n",
       "       'olympiatoppen', 'omkomme', 'opec', 'oppvarming', 'parti',\n",
       "       'partileder', 'pasient', 'passasjer', 'pave', 'pensjon',\n",
       "       'pensjonist', 'peso', 'planet', 'politi', 'politikk', 'politisk',\n",
       "       'prest', 'prosent', 'pågripe', 'ran', 'rasisme', 'regnskog',\n",
       "       'religion', 'rente', 'røkke', 'sas', 'schibsted', 'selskap',\n",
       "       'sentralbank', 'sentralbanksjef', 'sikte', 'skade', 'skatt',\n",
       "       'skogbrann', 'skole', 'snøskred', 'sokkel', 'soldat', 'spise',\n",
       "       'statoil', 'statoilhydro', 'statsminister', 'stora', 'strandson',\n",
       "       'strømpris', 'student', 'svenskehandel', 'svinesund', 'sykdom',\n",
       "       'sykefravær', 'sykehus', 'systembolag', 'sælen', 'takstmann',\n",
       "       'telenor', 'tiltale', 'tine', 'tingrett', 'tog', 'toll', 'toller',\n",
       "       'tollvesenet', 'trafikk', 'trillemarka', 'tv', 'udi', 'ulv',\n",
       "       'ulykke', 'undervisning', 'universitet', 'usa', 'utdanning',\n",
       "       'utenriksminister', 'utlendingsdirektoratet', 'utmark', 'utslipp',\n",
       "       'uvær', 'valg', 'valgkamp', 'valla', 'velger', 'verft',\n",
       "       'videregående', 'ytringsfrihet', 'økonomi'], dtype='<U178')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_vectorizer = TfidfVectorizer(**{'tokenizer': lambda x: x.split(), 'vocabulary': custom_vocab, 'min_df': 1, 'max_features': None, 'norm': 'l2', 'use_idf': True})\n",
    "vocab_train_x = vocab_vectorizer.fit_transform(train_X[corpus])\n",
    "vocab_validation_x = vocab_vectorizer.transform(validation_X[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19823, 2320)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48166734944694795"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB(**{'alpha': 0.001})\n",
    "clf.fit(vocab_train_x, train_y)\n",
    "\n",
    "preds = clf.predict(vocab_validation_x)\n",
    "np.mean(preds == validation_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
