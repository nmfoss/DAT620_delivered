{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = pd.read_pickle('../data/labeled_data_pos_ont_nn.pkl')\n",
    "drop_trash = (labeled_data['Aggr.Label'] < 90) & (labeled_data['NN_bool'] == False)\n",
    "labeled_data = labeled_data[drop_trash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features = ['Adjective', 'Verb', 'Noun']\n",
    "ont_features = ['Underspecified', 'Artifact', 'Object', 'Group', 'Human', 'Natural', 'LanguageRepresentation', 'Living', 'GeopoliticalPlace', 'BodyPart', 'Instrument', 'Place', '3rdOrderEntity', 'Mental', 'Purpose', 'Social', 'Institution', 'Plant', 'Imagerepresentation', 'Creature', 'Animal', 'Comestible', 'Quantity', 'Building', 'Substance', 'Part', 'Property', 'BoundedEvent', 'Agentive', 'Communication', 'Garment', 'Furniture', 'Vehicle', '1stOrderEntity', 'Covering', 'Liquid', 'Time', 'UnboundedEvent', 'Physical', 'Dynamic', 'Domain', 'Existence', 'Location', 'Manner', 'Container', 'Condition', 'Static', '2ndOrderEntity', 'Phenomenal', 'MoneyRepresentation', 'Experience', 'Relation', 'Form', 'Representation', 'Stimulating', 'Colour', 'Cause', 'Occupation', 'Possession', 'Artwork', 'Software']\n",
    "numerical_features = ['Raw_len', 'Raw_word_count']\n",
    "categorical_features = ['Label', 'Aggr.Label', 'Source', 'CoderId']\n",
    "text_features = ['Lemma_stripped', 'Raw', 'Lemma']\n",
    "fastt_features = ['Raw_FT_mean', 'Lemma_FT_mean']\n",
    "features = pos_features + ont_features + numerical_features + text_features + fastt_features + categorical_features\n",
    "\n",
    "fastt = 'Raw_FT_mean'\n",
    "corpus = 'Lemma'\n",
    "target = 'Aggr.Label'\n",
    "#target = 'Label'\n",
    "\n",
    "\n",
    "train_X, validation_X, train_y, validation_y = train_test_split(\n",
    "    labeled_data[features],\n",
    "    labeled_data[target],\n",
    "    test_size=0.33,\n",
    "    random_state=1,\n",
    "    stratify=labeled_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(**{'max_df': 0.3, 'max_features': None, 'norm': 'l2', 'strip_accents': 'ascii', 'use_idf': False})\n",
    "train_x = vectorizer.fit_transform(train_X[corpus])\n",
    "validation_x = vectorizer.transform(validation_X[corpus])\n",
    "\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_tfidf_means(X, Y, c, words, n):\n",
    "    class_ids = np.where(Y == c)\n",
    "    return sorted( list( zip(words, X[class_ids].mean(0).getA1())), key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "def get_corpus_tfidf_means(words, X, n):\n",
    "    return sorted( list( zip(words, X.mean(0).getA1())), key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "def get_accumulated_ranks(words, X, n):\n",
    "    l = len(words)\n",
    "\n",
    "    counts = Counter()\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        \n",
    "        row = np.squeeze(X[i].toarray())\n",
    "        top_id = np.argsort(row)[::-1][:10]\n",
    "        counts.update([words[k] for k in top_id if row[k] != 0])\n",
    "\n",
    "    count_words = [(k, v) for k,v in counts.items()]\n",
    "\n",
    "    return sorted( count_words, key=lambda x: x[1], reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hun', 1813),\n",
       " ('norge', 1603),\n",
       " ('norsk', 1588),\n",
       " ('du', 1318),\n",
       " ('krone', 1304),\n",
       " ('prosent', 1204),\n",
       " ('man', 1057),\n",
       " ('land', 1036),\n",
       " ('oslo', 1007),\n",
       " ('politi', 933),\n",
       " ('mann', 918),\n",
       " ('gar', 873),\n",
       " ('mene', 833),\n",
       " ('million', 822),\n",
       " ('sak', 746),\n",
       " ('selskap', 735),\n",
       " ('vg', 734),\n",
       " ('barn', 730),\n",
       " ('kvinne', 626),\n",
       " ('liten', 565),\n",
       " ('slik', 535),\n",
       " ('vise', 528),\n",
       " ('gammel', 523),\n",
       " ('usa', 519),\n",
       " ('der', 508)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_corpus_top = get_accumulated_ranks(words, train_x, 25)\n",
    "count_corpus_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hun', 0.036439797563380574),\n",
       " ('norsk', 0.03262615601881231),\n",
       " ('norge', 0.03254298717974614),\n",
       " ('du', 0.027515269834434756),\n",
       " ('krone', 0.02557657338590981),\n",
       " ('mene', 0.025154597338225743),\n",
       " ('prosent', 0.02483493633248241),\n",
       " ('land', 0.023895084761470196),\n",
       " ('man', 0.023646986503030508),\n",
       " ('gar', 0.02279994195799935),\n",
       " ('liten', 0.02206173553431721),\n",
       " ('oslo', 0.02152405540694742),\n",
       " ('slik', 0.021472865798822325),\n",
       " ('mann', 0.02092330648709083),\n",
       " ('tid', 0.020362246982219372),\n",
       " ('denne', 0.02033633483154298),\n",
       " ('der', 0.0200578024957807),\n",
       " ('vise', 0.019176979966682873),\n",
       " ('million', 0.01861563884848365),\n",
       " ('ntb', 0.01858025768358999),\n",
       " ('gang', 0.018271115039061973),\n",
       " ('politi', 0.018214501494854263),\n",
       " ('sak', 0.01794386408283429),\n",
       " ('hva', 0.01789256751882543),\n",
       " ('sta', 0.017507197120050774)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_top = get_corpus_tfidf_means(words, train_x, 25)\n",
    "corpus_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('norsk', 0.06255350273938819),\n",
       " ('norge', 0.05356272702004951),\n",
       " ('land', 0.049224310599757584),\n",
       " ('prosent', 0.04746801690737708),\n",
       " ('krone', 0.03882839182744247),\n",
       " ('ke', 0.03583877850506815),\n",
       " ('usa', 0.03189491497061322),\n",
       " ('sverige', 0.03185911208669827),\n",
       " ('mene', 0.03051383703049594),\n",
       " ('du', 0.02862267635405802),\n",
       " ('svensk', 0.026645872341275918),\n",
       " ('ntb', 0.026628885363830516),\n",
       " ('verden', 0.02581254542222896),\n",
       " ('hun', 0.023391529341185595),\n",
       " ('million', 0.022930952500949807),\n",
       " ('vare', 0.022262905149953896),\n",
       " ('eu', 0.022227974789290138),\n",
       " ('handle', 0.02219894164532183),\n",
       " ('aftenposten', 0.022049811492129683),\n",
       " ('mellom', 0.02173980014570053),\n",
       " ('slik', 0.020741032949343773),\n",
       " ('toll', 0.02064209208301835),\n",
       " ('man', 0.020641284881917823),\n",
       " ('nordmann', 0.020591179228851692),\n",
       " ('sist', 0.020299945958600362)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mean = get_class_tfidf_means(train_x, train_y, 18, words, 25)\n",
    "class_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_intersect = set([x[0] for x in count_corpus_top]) & set([x[0] for x in corpus_top])\n",
    "corpus_intersect_prop = len(corpus_intersect)/25\n",
    "corpus_intersect_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6 0.03465671190031781\n",
      "2 0.68 0.022801795893658883\n",
      "3 0.64 0.07430762245876002\n",
      "4 0.68 0.03743126671038693\n",
      "5 0.6 0.023911617817686526\n",
      "6 0.6 0.029460727437824748\n",
      "7 0.76 0.026686172627755637\n",
      "8 0.6 0.03157947838369571\n",
      "9 0.56 0.022297331382737224\n",
      "10 0.68 0.05695404328305504\n",
      "12 0.56 0.1344397921606215\n",
      "13 0.68 0.03611965898199062\n",
      "14 0.56 0.019371437219391614\n",
      "15 0.64 0.0811178933562024\n",
      "16 0.64 0.08096655400292589\n",
      "17 0.64 0.05513797104373707\n",
      "18 0.48 0.005599556071230389\n",
      "19 0.68 0.04787368208646522\n",
      "20 0.6 0.07592190889370933\n",
      "21 0.52 0.00721384250617969\n",
      "23 0.76 0.0320334964435252\n",
      "24 0.6 0.01992634818140544\n",
      "25 0.4 0.026686172627755637\n",
      "26 0.6 0.017504918528981485\n"
     ]
    }
   ],
   "source": [
    "class_labels = np.unique(train_y)\n",
    "corpus_top_words = set([t[0] for t in corpus_top])\n",
    "\n",
    "for c in class_labels:\n",
    "    top = get_class_tfidf_means(train_x, train_y, c, words, len(corpus_top_words))\n",
    "    top_words = set([t[0] for t in top])\n",
    "    intersect = top_words & corpus_top_words\n",
    "    intersect_prop = len(intersect)/len(corpus_top_words)\n",
    "    class_prop = len(np.where(train_y == c)[0]) / len(train_y)\n",
    "    print(c,intersect_prop, class_prop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_KBest(words, c, K, x, y):\n",
    "    \n",
    "    words = np.array(words)\n",
    "    msk = np.zeros(words.shape[0], dtype=bool)\n",
    "    for cl in c:\n",
    "        class_y = y.copy()\n",
    "        class_y[class_y != cl] = 0\n",
    "        selected = SelectKBest(chi2, k=K).fit(x, class_y)\n",
    "        selected_words = selected.get_support()\n",
    "        msk = msk | selected_words\n",
    "        \n",
    "    return words[msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vocab = get_class_KBest(words, class_labels, 100, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_vectorizer = TfidfVectorizer(**{'max_df': 0.3, 'max_features': None, 'norm': 'l2', 'strip_accents': 'ascii', 'use_idf': False})\n",
    "vocab_train_x = vocab_vectorizer.fit_transform(train_X[corpus])\n",
    "vocab_validation_x = vocab_vectorizer.transform(validation_X[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4870954526833265"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB(**{'alpha': 0.001})\n",
    "clf.fit(vocab_train_x, train_y)\n",
    "\n",
    "preds = clf.predict(vocab_validation_x)\n",
    "np.mean(preds == validation_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
